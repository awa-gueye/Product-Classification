# Product Classification - Classification des biens de consommation

> SystÃ¨me de classification automatique de produits e-commerce utilisant l'apprentissage automatique et le deep learning

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)

##  Table des matiÃ¨res

- [Ã€ propos du projet](#Ã -propos-du-projet)
- [CatÃ©gories de produits](#catÃ©gories-de-produits)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Architecture](#architecture)
- [Structure du projet](#structure-du-projet)
- [Technologies utilisÃ©es](#technologies-utilisÃ©es)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [ModÃ¨les de Machine Learning](#modÃ¨les-de-machine-learning)
- [API REST](#api-rest)
- [Application Web](#application-web)
- [DÃ©ploiement avec Docker](#dÃ©ploiement-avec-docker)
- [RÃ©sultats](#rÃ©sultats)
- [PrÃ©sentation](#prÃ©sentation)
- [MÃ©thodologie](#mÃ©thodologie)
- [Contribution](#contribution)
- [Licence](#licence)

## Ã€ propos du projet

Ce projet implÃ©mente un systÃ¨me complet de classification de produits e-commerce capable de prÃ©dire automatiquement la catÃ©gorie d'un produit Ã  partir de :

- **ğŸ“ Texte** : Description du produit
- **ğŸ–¼ï¸ Image** : Photo du produit  

Le systÃ¨me utilise des techniques avancÃ©es de machine learning et deep learning pour offrir des prÃ©dictions prÃ©cises et rapides, idÃ©ales pour des applications e-commerce en production.

##  CatÃ©gories de produits

Le systÃ¨me classifie les produits dans **7 catÃ©gories** principales :

| IcÃ´ne | CatÃ©gorie | Description |
|-------|-----------|-------------|
| ğŸ‘¶ | **Baby Care** | Produits de soins pour bÃ©bÃ©s |
| ğŸ’„ | **Beauty and Personal Care** | Produits de beautÃ© et soins personnels |
| ğŸ’» | **Computers** | Ordinateurs et accessoires informatiques |
| ğŸ¨ | **Home Decor & Festive Needs** | DÃ©coration et articles festifs |
| ğŸ›‹ï¸ | **Home Furnishing** | Mobilier et ameublement |
| ğŸ³ | **Kitchen & Dining** | Articles de cuisine et salle Ã  manger |
| âŒš | **Watches** | Montres et accessoires horlogers |

## FonctionnalitÃ©s

### CapacitÃ©s de classification

- âœ… Classification basÃ©e sur le texte (description produit)
- âœ… Classification basÃ©e sur l'image (photo produit)
- âœ… Scores de confiance pour chaque prÃ©diction
- âœ… ProbabilitÃ©s dÃ©taillÃ©es par catÃ©gorie

### ğŸ–¥ï¸ Interface utilisateur (Streamlit)

- âœ… Interface moderne et intuitive
- âœ… Upload d'images avec prÃ©visualisation
- âœ… Saisie de description textuelle
- âœ… Visualisation des rÃ©sultats en temps rÃ©el
- âœ… Dashboard analytique avec graphiques interactifs
- âœ… Historique complet des prÃ©dictions
- âœ… Export des donnÃ©es en CSV
- âœ… Design responsive (desktop/mobile)

###  API REST (FastAPI)

- âœ… Endpoints de prÃ©diction (texte, image, multimodal)
- âœ… Documentation Swagger auto-gÃ©nÃ©rÃ©e
- âœ… Documentation ReDoc interactive
- âœ… Validation des donnÃ©es avec Pydantic
- âœ… Gestion robuste des erreurs
- âœ… Support CORS configurÃ©
- âœ… Health check endpoint

##  Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Interface Utilisateur           â”‚
â”‚         (Streamlit Web App)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
            HTTP Requests
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           API REST (FastAPI)            â”‚
â”‚  - /predict/text                        â”‚
â”‚  - /predict/image                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
          Chargement des modÃ¨les
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ModÃ¨les ML/DL                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ModÃ¨le Texte (SVM + TF-IDF)   â”‚    â”‚
â”‚  â”‚  Accuracy: 95,57%              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  ModÃ¨le Image (VGG16)          â”‚    â”‚
â”‚  â”‚  Accuracy: 78.48%              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Structure du projet

```
Product-Classification/
â”‚
â”œâ”€â”€ ğŸ“‚ api/                           # API FastAPI
â”‚   â”œâ”€â”€ main.py                       # Point d'entrÃ©e de l'API
â”‚   â”œâ”€â”€ requirements.txt                     
â”‚   â””â”€â”€ Dockerfile                    # Configuration
â”‚
â”œâ”€â”€ ğŸ“‚ app/                           # Application Streamlit
â”‚   â””â”€â”€ streamlit_app.py              # Interface web
â”‚
â”œâ”€â”€ ğŸ“‚ Data/                           # DonnÃ©es de l'Ã©tude
â”‚   â””â”€â”€ Flipkart/ 
â”‚       â”œâ”€â”€ images/                     # Dossier contenant les images           
â”‚       â””â”€â”€ flipkart_com-ecommerce_sample_1050.csv  # fichier des donnÃ©es brutes
â”‚
â”œâ”€â”€ ğŸ“‚ models/                        # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”‚   â”œâ”€â”€ final_best_model.pkl          # ModÃ¨le SVM (texte)
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl          # Vectoriseur TF-IDF
â”‚   â”œâ”€â”€ cnn_final.keras               # VGG16 (image)
â”‚   â””â”€â”€ label_encoders.pkl            # Encodeurs de labels
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                              # Notebooks du projet
â”‚   â”œâ”€â”€ n1_analyse_exploratoire.ipynb          # Analyse exploratoire des donnÃ©es textuelles
â”‚   â”œâ”€â”€ n2_prepocessing_featuring.ipynb        # Preprocessing et featuring des textes
â”‚   â”œâ”€â”€ n3_modelisation_text.ipynb             # ModÃ©lisation des donnÃ©es textuelles
â”‚   â”œâ”€â”€ n4_exploration_image.ipynb             # Analyse exploratoire des images
â”‚   â””â”€â”€ n5_deep_mearning_supervise.ipynb       # ModÃ©lisation des images
â”‚
â”œâ”€â”€ ğŸ“„ save_transformers.py           # Sauvegarde des transformateurs
â”œâ”€â”€ ğŸ“„ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ ğŸ“„ docker-compose.yml             # Configuration Docker Compose
â”œâ”€â”€ ğŸ“„ .python-version                # Version Python (3.12)
â”œâ”€â”€ ğŸ“„ .gitignore                     # Fichiers Ã  ignorer
â”‚
â””â”€â”€ ğŸ“„ README.md                      # Ce fichier
```

## Technologies utilisÃ©es

### Machine Learning & Deep Learning Technologies

#### Deep Learning Frameworks & Models
- **TensorFlow/Keras** - Deep learning framework pour la classification d'images et modÃ¨les de vision par ordinateur
- **EfficientNetB0** - Architecture CNN avancÃ©e pour la classification d'images 
- **VGG16** - Architecture CNN Ã©prouvÃ©e utilisÃ©e pour la classification d'images
- **MobileNetV3-Small** - ModÃ¨le lÃ©ger optimisÃ© pour les applications en temps rÃ©el
- **CNN Custom (baseline)** - Architecture CNN personnalisÃ©e dÃ©veloppÃ©e comme modÃ¨le de base

#### Machine Learning Algorithms (NLP & Classification)
- **Scikit-learn** - BibliothÃ¨que complÃ¨te d'algorithmes de machine learning
- **Support Vector Machines (SVM)** - Algorithmes pour la classification textuelle avec noyaux linÃ©aires et RBF
- **Logistic Regression** - ModÃ¨le de rÃ©gression logistique pour la classification binaire et multiclasse
- **Random Forest** - Algorithme d'ensemble par forÃªts alÃ©atoires pour la classification
- **Gradient Boosting** - MÃ©thodes de boosting pour amÃ©liorer les performances de prÃ©diction
- **XGBoost** - ImplÃ©mentation optimisÃ©e du gradient boosting
- **TF-IDF + SVM** - Pipeline NLP pour la classification textuelle (meilleur modÃ¨le textuel)

#### Preprocessing & Feature Engineering
- **TF-IDF Vectorization** - Extraction de caractÃ©ristiques textuelles pour le NLP
- **Image Augmentation** - Techniques d'augmentation d'images pour amÃ©liorer la robustesse des modÃ¨les
- **Feature Scaling** - Normalisation et standardisation des caractÃ©ristiques
- **Dimensionality Reduction** - Techniques pour rÃ©duire la dimensionnalitÃ© des donnÃ©es

#### Model Evaluation & Optimization
- **Cross-Validation** - Validation croisÃ©e pour l'Ã©valuation robuste des modÃ¨les
- **Hyperparameter Tuning** - Optimisation des hyperparamÃ¨tres via Grid Search et Random Search
- **Performance Metrics** - Accuracy, Precision, Recall, F1-Score, Confusion Matrix
- **Model Persistence** - Sauvegarde et chargement des modÃ¨les entraÃ®nÃ©s (pickle, h5)


### Backend & API

- **FastAPI**  - Framework web moderne et performant
- **Uvicorn** - Serveur ASGI haute performance
- **Pydantic** - Validation et sÃ©rialisation des donnÃ©es

### Frontend & Visualisation

- **Streamlit** - Framework pour interfaces web interactives
- **Plotly** - BibliothÃ¨que de visualisation interactive
- **Pandas** - Manipulation et analyse de donnÃ©es

### Preprocessing & Utilities

- **NumPy** - Calcul numÃ©rique
- **Pillow** - Traitement d'images
- **Python-multipart** - Gestion des uploads de fichiers

### DÃ©ploiement

- **Docker** - Containerisation des applications
- **Docker Compose** - Orchestration multi-conteneurs

## Installation

### PrÃ©requis

- Python 3.9 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Git
- (Optionnel) Docker et Docker Compose

### Ã‰tapes d'installation

1. **Cloner le repository**

```bash
git clone https://github.com/awa-gueye/Product-Classification.git
cd Product-Classification
```

2. **CrÃ©er un environnement virtuel** (fortement recommandÃ©)

```bash
python -m venv venv

# Sur Windows
venv\Scripts\activate

# Sur Linux/Mac
source venv/bin/activate
```

3. **Installer les dÃ©pendances**

```bash
pip install -r requirements.txt
```

## Utilisation

### Etape 1 : Lancer l'API FastAPI

```bash
# Depuis le dossier api
cd api
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**L'API sera accessible Ã  :**
- **Serveur** : http://localhost:8000
- **Documentation Swagger** : http://localhost:8000/docs
- **Documentation ReDoc** : http://localhost:8000/redoc

### Etape 2 : Lancer l'application Streamlit

```bash
# Depuis le dossier app
cd app
streamlit run streamlit_app.py
```

**L'application web sera accessible Ã  :** http://localhost:8501


## ModÃ¨les de Machine Learning

### 1. ModÃ¨les Texte

**Architecture et workflow** :

```
Texte brut (nom du produit, description produit)
    â†“
[Preprocessing]
  - Nettoyage
  - Tokenisation
  - Suppression stop words
  - Lemmatisation
    â†“
[TF-IDF Vectorization]
  - N-grams (1-2)
  - Max features: 3100
    â†“
[SVM Classifier (Meilleur modÃ¨le)]
  - C optimisÃ©
  - Gamma optimisÃ©
    â†“
CatÃ©gorie prÃ©dite + probabilitÃ©s
```

**Performances** :
- **Accuracy** : 95.57%
- **F1-Score** : 95.49%
- **Precision** : 95.62%
- **Recall** : 95.56%

**Fichiers associÃ©s** :
- `models/final_best_model.pkl` - ModÃ¨le SVM entraÃ®nÃ©
- `models/tfidf_vectorizer.pkl` - Vectoriseur TF-IDF

### 2. ModÃ¨les Image

**Architecture dÃ©taillÃ©e** :

```
Image d'entrÃ©e (224x224x3)
    â†“
[VGG16]
  - PrÃ©-entraÃ®nÃ©
  - Poids gelÃ©s (frozen layers)
    â†“
[GlobalAveragePooling2D]
    â†“
[Dense Layer 512]
  - BatchNormalization
  - Dropout (0.5)
  - Activation: ReLU
    â†“
[Dense Layer 256]
  - BatchNormalization
  - Dropout (0.4)
  - Activation: ReLU
    â†“
[Dense Layer 7]
  - Activation: Softmax
    â†“
CatÃ©gorie prÃ©dite + probabilitÃ©s
```

**CaractÃ©ristiques d'entraÃ®nement** :
- Transfer learning avec ResNet50
- Fine-tuning des derniÃ¨res couches
- Data augmentation : rotation, flip horizontal, zoom, shear
- Early stopping 
- Optimiseur : Adam
- Loss : Categorical Crossentropy

**Performances** :
- **Accuracy** : 78.48%
- **F1-Score** : 78.62%
- **EntraÃ®nement** : 15 epochs 

**Fichier associÃ©** :
- `models/label_encoders.pkl` - Encodeurs de labels
- `models/cnn_final.keras` - ModÃ¨le CNN entraÃ®nÃ©

## API REST

### Endpoints disponibles

| MÃ©thode | Endpoint | Description | Corps de la requÃªte | RÃ©ponse |
|---------|----------|-------------|---------------------|---------|
| GET | `/` | Informations API | - | JSON metadata |
| GET | `/health` | Ã‰tat de santÃ© | - | Status message |
| GET | `/categories` | Liste des catÃ©gories | - | Array de catÃ©gories |
| POST | `/predict/text` | Classification texte | `{"text": "..."}` | PrÃ©diction + probas |
| POST | `/predict/image` | Classification image | `file: image` | PrÃ©diction + probas |

### Exemples d'utilisation

#### Python (avec requests)

```python
import requests

# Classification par texte
response = requests.post(
    "http://localhost:8000/predict/text",
    json={"text": "Montre analogique pour homme avec bracelet en cuir vÃ©ritable"}
)
result = response.json()
print(f"CatÃ©gorie: {result['predicted_class']}")
print(f"Confiance: {result['confidence']:.2%}")

# Classification par image
with open("product_image.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8000/predict/image",
        files={"file": f}
    )
result = response.json()
print(f"CatÃ©gorie: {result['predicted_class']}")

```

#### cURL

```bash
# Classification texte
curl -X POST "http://localhost:8000/predict/text" \
     -H "Content-Type: application/json" \
     -d '{"text": "Ordinateur portable 15 pouces gaming RTX 4070"}'

# Classification image
curl -X POST "http://localhost:8000/predict/image" \
     -F "file=@product.jpg"

```

### Format de rÃ©ponse

```json
{
  "predicted_class": "Watches",
  "confidence": 0.8523,
  "probabilities": {
    "Baby Care": 0.0234,
    "Beauty and Personal Care": 0.0456,
    "Computers": 0.0123,
    "Home Decor & Festive Needs": 0.0289,
    "Home Furnishing": 0.0156,
    "Kitchen & Dining": 0.0219,
    "Watches": 0.8523
  },
  "model_used": "text",
  "timestamp": "2024-01-15T10:30:45.123456"
}
```

## Application Web - Product Classifier Pro

L'application Streamlit offre une interface professionnelle de classification de produits pour e-commerce avec un design bleu marine (#1E3A8A) et or (#D4AF37) avec thÃ¨me clair/sombre adaptatif.

### Navigation Principale
- **ğŸ  HOME** : Page d'accueil avec prÃ©sentation, fonctionnalitÃ©s, catÃ©gories et performances
- **ğŸ“¸ IMAGE CLASSIFICATION** : Classification d'images simples ou par lot avec prÃ©visualisation
- **ğŸ“ TEXT CLASSIFICATION** : Classification de descriptions produit uniques ou multiples
- **ğŸ“Š DASHBOARD** : Analytics en temps rÃ©el avec visualisations interactives
- **ğŸŒ™/â˜€ï¸** : Bouton de changement de thÃ¨me clair/sombre

### FonctionnalitÃ©s ClÃ©s
1. **Classification Simple** : Upload d'image ou saisie de texte pour classification instantanÃ©e
2. **Traitement Batch** : 
   - Images multiples (JPG/PNG) avec aperÃ§u
   - Textes multiples via CSV ou saisie manuelle
3. **Visualisation des rÃ©sultats** :
   - Jauge de confiance interactive
   - Graphique de probabilitÃ©s par catÃ©gorie
   - Affichage de la catÃ©gorie prÃ©dite
4. **Analytics AvancÃ©s** :
   - MÃ©triques de performance des modÃ¨les
   - Historique complet des prÃ©dictions
   - Graphiques comparatifs et distributions
   - Export des donnÃ©es au format CSV

### Design & ExpÃ©rience Utilisateur
- **Palette** : Bleu marine (#1E3A8A) et or (#D4AF37)
- **ThÃ¨mes** : Mode clair et sombre interchangeables
- **Responsive** : AdaptÃ© desktop et mobile
- **Interactions** : Hover effects, transitions fluides, feedback visuel
- **Visualisations** : Plotly pour graphiques interactifs et modernes

### DonnÃ©es & CatÃ©gories
- **7 catÃ©gories** : Baby Care, Beauty & Personal Care, Computers, Home Decor & Festive Needs, Home Furnishing, Kitchen & Dining, Watches
- **ModÃ¨les** : VGG16 pour images, TF-IDF+SVM pour texte
- **Performance** : 95.6% accuracy (texte), 78.5% accuracy (images)

## Outils de dÃ©ploiement testÃ©s

### ğŸŒ Plateformes Cloud & HÃ©bergement
- **Streamlit Cloud** - HÃ©bergement principal de l'application frontend (dÃ©ploiement continu via GitHub)
- **Render** - DÃ©ploiement du backend FastAPI (API de classification)
- **Railway** - TestÃ© pour le dÃ©ploiement du backend

### ğŸ³ Conteneurisation & Orchestration
- **Docker** - Conteneurisation de l'application
- **Docker Compose** - Orchestration multi-conteneurs pour dÃ©veloppement local

### Backend & API
- **FastAPI** - Framework backend moderne avec documentation OpenAPI automatique
- **Uvicorn** - Serveur ASGI haute performance pour FastAPI

### Gestion des dÃ©pendances & Environnements
- **Pip** - Gestionnaire de paquets Python standard
- **requirements.txt** - Fichier de dÃ©pendances versionnÃ©
- **virtualenv/venv** - Environnements virtuels isolÃ©s

### CI/CD & Automatisation
- **Automatisation Git** - DÃ©ploiement continu sur push vers main

### Stockage
- **Google Drive** - Pour le stockage des fichiers .pkl et .keras

NB : le dÃ©ploiement n'a pas pu Ãªtre effectuÃ© du fait des erreurs rencontrÃ©s pour le tÃ©lÃ©chargement du modÃ¨le de deep learning

## RÃ©sultats

### Comparaison des performances par modalitÃ©

| ModalitÃ© | ModÃ¨le | Accuracy | F1-Score | PrÃ©cision | Rappel |
|----------|--------|----------|----------|-----------|--------|
| **Texte** | SVM (TF-IDF) | **95.57%** | **0.955** | 0.956 | 0.955 |
| **Image** | VGG16 | 78.48% | 0.7862 | - | - |

### Points clÃ©s des rÃ©sultats

- âœ… **ModÃ¨le texte** : Performances excellentes avec 95.57% d'accuracy
- âœ… **ModÃ¨le image** : RÃ©sultats corrects compte tenu de la complexitÃ© visuelle
- âœ… **Transfer learning** : AmÃ©lioration significative grÃ¢ce Ã  ResNet50 prÃ©-entraÃ®nÃ©
- âœ… **Temps d'infÃ©rence** : Rapides et adaptÃ©s Ã  la production

### Matrice de confusion (ModÃ¨le Texte SVM)

```
                    PrÃ©dictions
              BC   BP   CO   HD   HF   KD   WA
RÃ©el    BC   [145   2    0    1    1    0    1]  
        BP   [ 1  143   0    2    2    1    1]  
        CO   [ 0    0  148   0    1    1    0] 
        HD   [ 2    1    0  141   3    3    0] 
        HF   [ 1    2    1    2  140   4    0]  
        KD   [ 0    1    1    3    3  142   0] 
        WA   [ 0    0    0    0    0    0  150] 

LÃ©gende des catÃ©gories :
BC = Baby Care
BP = Beauty and Personal Care
CO = Computers
HD = Home Decor & Festive Needs
HF = Home Furnishing
KD = Kitchen & Dining
WA = Watches
```

**Observations** :
- Excellente performance sur la catÃ©gorie "Watches" (100%)
- Performance solide et Ã©quilibrÃ©e sur toutes les catÃ©gories
- Peu de confusions entre catÃ©gories trÃ¨s diffÃ©rentes
- Quelques confusions marginales sur des catÃ©gories proches (ex: Home Decor vs Home Furnishing)

## PrÃ©senation 
Ci-dessous le lien pour la prÃ©sentaion du projet :
https://www.canva.com/design/DAHAVETLstM/8XIpfnZDtlYXgHK9Ca-mbg/edit?utm_content=DAHAVETLstM&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton

## MÃ©thodologie

### 1. Preprocessing des donnÃ©es

**DonnÃ©es textuelles** :
1. Nettoyage du texte
   - Suppression de la ponctuation
   - Conversion en minuscules
   - Suppression des caractÃ¨res spÃ©ciaux
2. Tokenisation
3. Suppression des stop words
4. Lemmatisation pour normalisation

**DonnÃ©es images** :
1. Redimensionnement Ã  224x224 pixels
2. Normalisation des valeurs de pixels (0-1)
3. Data augmentation :
   - Rotation alÃ©atoire (Â±20Â°)
   - Flip horizontal
   - Zoom alÃ©atoire (Â±20%)
   - Shear transformation

### 2. Feature Engineering

**ModalitÃ© texte** :
- Vectorisation TF-IDF (Term Frequency-Inverse Document Frequency)
- N-grams : unigrammes et bigrammes (1-2)
- Nombre maximal de features : 10000 termes
- Normalisation L2

**ModalitÃ© image** :
- Extraction de features via ResNet50 prÃ©-entraÃ®nÃ© (ImageNet)
- Fine-tuning des couches supÃ©rieures
- Ajout de couches denses personnalisÃ©es
- Batch normalization et dropout pour rÃ©gularisation

### 3. ModÃ©lisation et expÃ©rimentation

**ModÃ¨les testÃ©s pour le texte** :
- Support Vector Machine (SVM) â† **Retenu** (meilleure performance)
- Logistic Regression
- Random Forest
- XGBoost
- Gradient Boosting

**Architectures testÃ©es pour les images** :
- CNN personnalisÃ©
- VGG16 â† **Retenu** (bon compromis performance/complexitÃ©)
- EfficientNetB0
- MobilNet

**StratÃ©gies de fusion** :
- Early fusion (concatÃ©nation de features)
- Late fusion (combinaison de prÃ©dictions)

### 4. Ã‰valuation et validation

**MÃ©triques utilisÃ©es** :
- Accuracy
- F1-Score
- Precision, Recall
- Matrice de confusion

**Validation** :
- Train/Val/Test split (70/15/15)
- Validation croisÃ©e pour optimisation des hyperparamÃ¨tres

## Contribution

Les contributions sont les bienvenues et encouragÃ©es ! Voici comment participer :

### Comment contribuer

1. **Fork** le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ© (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une **Pull Request**

### Guidelines de contribution

- Suivre les conventions PEP 8 pour le code Python
- Ajouter des tests pour les nouvelles fonctionnalitÃ©s
- Mettre Ã  jour la documentation si nÃ©cessaire
- Utiliser des messages de commit clairs et descriptifs
- Documenter les nouvelles fonctions et classes

### IdÃ©es de contribution

- Ajouter de nouvelles catÃ©gories de produits
- Tester d'autres architectures (BERT, Vision Transformer)
- AmÃ©liorer le dashboard avec de nouvelles visualisations
- ImplÃ©menter l'authentification API
- Ajouter le support multilingue
- CrÃ©er des notebooks d'analyse supplÃ©mentaires

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.

**RÃ©sumÃ© de la licence MIT** :
- âœ… Utilisation commerciale autorisÃ©e
- âœ… Modification autorisÃ©e
- âœ… Distribution autorisÃ©e
- âœ… Utilisation privÃ©e autorisÃ©e
- âš ï¸ Aucune garantie fournie
- âš ï¸ ResponsabilitÃ© limitÃ©e

## Auteurs

**Awa GUEYE, Mariane DAIFERLE, Gilbert OUMSAORE, Naba Amadou Seydou TOURE**

- ğŸŒ GitHub : [@awa-gueye](https://github.com/awa-gueye)
- ğŸ“ Projet : [Product-Classification](https://github.com/awa-gueye/Product-Classification)


## Ressources additionnelles
- [Documentation TensorFlow](https://www.tensorflow.org/)
- [Documentation Scikit-learn](https://scikit-learn.org/)
- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation Streamlit](https://docs.streamlit.io/)
- [Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)

---

[â¬† Retour en haut](#-product-classification---classification-des-biens-de-consommation)